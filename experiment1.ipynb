{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams, pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-07   1.00000000e-07   1.00000000e-07]\n",
      "[  1.00000000e-07   9.99999900e-01   1.00000000e-07]\n",
      "[  1.00000000e-07   1.00000000e-07   1.00000000e-07]\n",
      "[  1.00000000e-07   1.00000000e-07   9.99999900e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0295239877834463"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math as math\n",
    "\n",
    "y_true = np.array([[0, 0, 0], [1, 1, 0], [0, 1, 0], [0, 0, 0]])\n",
    "y_pred = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0], [0, 0, 1]])\n",
    "\n",
    "y_pred = np.clip(y_pred, e, 1 - e)\n",
    "\n",
    "e = 0.0000001\n",
    "result = []\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred_i = np.clip(y_pred[i], e, 1-e)\n",
    "    print(y_pred_i)\n",
    "    result.append(-np.mean([y_true[i][j] * math.log(y_pred_i[j]) + (1 - y_true[i][j]) * math.log(1 - y_pred_i[j]) for j in range(len(y_pred_i))]))\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      " \n",
      "[[  1.00000000e-09   1.00000000e-09   1.00000000e-09]\n",
      " [  1.00000000e-09   9.99999999e-01   1.00000000e-09]\n",
      " [  1.00000000e-09   1.00000000e-09   1.00000000e-09]\n",
      " [  1.00000000e-09   1.00000000e-09   9.99999999e-01]]\n",
      "\n",
      "[[ -0.00000000e+00  -0.00000000e+00  -0.00000000e+00]\n",
      " [ -1.61180957e+01  -1.00000005e-07  -0.00000000e+00]\n",
      " [ -0.00000000e+00  -1.61180957e+01  -0.00000000e+00]\n",
      " [ -0.00000000e+00  -0.00000000e+00  -0.00000000e+00]]\n",
      " \n",
      "[[ -1.00000005e-07  -1.00000005e-07  -1.00000005e-07]\n",
      " [ -0.00000000e+00  -0.00000000e+00  -1.00000005e-07]\n",
      " [ -1.00000005e-07  -0.00000000e+00  -1.00000005e-07]\n",
      " [ -1.00000005e-07  -1.00000005e-07  -1.61180957e+01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0295239877834481"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math as math\n",
    "\n",
    "print(y_true)\n",
    "print(' ')\n",
    "print(y_pred)\n",
    "print('')\n",
    "\n",
    "\n",
    "o_terms = np.multiply(y_true, np.log(y_pred))\n",
    "z_terms = np.multiply(np.subtract(1, y_true), np.log(np.subtract(1, y_pred)))\n",
    "\n",
    "print(o_terms)\n",
    "print(' ')\n",
    "print(z_terms)\n",
    "\n",
    "o_result = []\n",
    "for i in range(len(y_pred)):\n",
    "    o_result.append([y_true[i][j] * math.log(y_pred[i][j]) for j in range(len(y_pred[i]))])\n",
    "#print(np.array(o_result))\n",
    "\n",
    "z_result = []\n",
    "for i in range(len(y_pred)):\n",
    "    z_result.append([(1 - y_true[i][j]) * math.log(1 - y_pred[i][j]) for j in range(len(y_pred[i]))])\n",
    "#print(np.array(z_result))\n",
    "\n",
    "terms = np.add(o_terms, z_terms)\n",
    "terms = np.negative(np.mean(terms))\n",
    "\n",
    "np.mean(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      " \n",
      "[[  1.00000000e-07   1.00000000e-07   1.00000000e-07]\n",
      " [  1.00000000e-07   9.99999900e-01   1.00000000e-07]\n",
      " [  1.00000000e-07   1.00000000e-07   1.00000000e-07]\n",
      " [  1.00000000e-07   1.00000000e-07   9.99999900e-01]]\n",
      "\n",
      "[[ -0.00000000e+00  -0.00000000e+00  -0.00000000e+00]\n",
      " [ -3.22361913e+01  -3.00000015e-07  -0.00000000e+00]\n",
      " [ -0.00000000e+00  -4.83542870e+01  -0.00000000e+00]\n",
      " [ -0.00000000e+00  -0.00000000e+00  -0.00000000e+00]]\n",
      " \n",
      "[[ -1.00000005e-07  -1.00000005e-07  -1.00000005e-07]\n",
      " [ -0.00000000e+00  -0.00000000e+00  -1.00000005e-07]\n",
      " [ -1.00000005e-07  -0.00000000e+00  -1.00000005e-07]\n",
      " [ -1.00000005e-07  -1.00000005e-07  -1.61180957e+01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0590479171896963"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math as math\n",
    "\n",
    "print(y_true)\n",
    "print(' ')\n",
    "print(y_pred)\n",
    "print('')\n",
    "\n",
    "o_weight = np.array([2, 3, 3])\n",
    "o_terms = np.multiply(np.multiply(y_true, np.log(y_pred)), o_weight)\n",
    "z_terms = np.multiply(np.subtract(1, y_true), np.log(np.subtract(1, y_pred)))\n",
    "\n",
    "print(o_terms)\n",
    "print(' ')\n",
    "print(z_terms)\n",
    "\n",
    "o_result = []\n",
    "for i in range(len(y_pred)):\n",
    "    o_result.append([y_true[i][j] * math.log(y_pred[i][j]) for j in range(len(y_pred[i]))])\n",
    "#print(np.array(o_result))\n",
    "\n",
    "z_result = []\n",
    "for i in range(len(y_pred)):\n",
    "    z_result.append([(1 - y_true[i][j]) * math.log(1 - y_pred[i][j]) for j in range(len(y_pred[i]))])\n",
    "#print(np.array(z_result))\n",
    "\n",
    "terms = np.add(o_terms, z_terms)\n",
    "terms = np.negative(np.mean(terms))\n",
    "\n",
    "np.mean(terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32.23619130191664"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.00000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "\n",
    "x_train = df_train['comment_text']\n",
    "y_train = df_train[categories].as_matrix()\n",
    "\n",
    "display(df_train.head())\n",
    "m = x_train.shape[0]\n",
    "display(f'total m = {m}')\n",
    "\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(texts=x_train)\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index)\n",
    "sequences = tokenizer.texts_to_sequences(texts=x_train)\n",
    "\n",
    "max_seq_len = 0\n",
    "for sequence in sequences:\n",
    "    max_seq_len = max(max_seq_len, len(sequence))\n",
    "\n",
    "print('max length {}'.format(max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "embedding_dim = 50\n",
    "weights = np.load('output/embedding_weights_20180312.npy')\n",
    "\n",
    "embedding = Embedding(vocabulary_size + 1, embedding_dim, weights=weights, trainable=False)\n",
    "\n",
    "from keras.layers import Bidirectional, LSTM, GRU, Dense\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "toxic_weighting = 2.0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_binary_crossentropy(target, output, from_logits=True):\n",
    "    target_bool = tf.equal(target, 0, name='target_boolean')\n",
    "    bool_filter = tf.reduce_all(target_bool, axis=1, name='boolean_filter')\n",
    "    \n",
    "    non_toxics = tf.boolean_mask(target, bool_filter, name='non_toxics')\n",
    "    non_toxics_output = tf.boolean_mask(output, bool_filter, name='non_toxics_output')\n",
    "    non_toxics_result = K.binary_crossentropy(non_toxics, non_toxics_output)\n",
    "#     print('non_toxics_result: {}'.format(non_toxics_result))\n",
    "    \n",
    "    toxics = tf.boolean_mask(target, ~bool_filter, name='toxics')\n",
    "    toxics_output = tf.boolean_mask(output, ~bool_filter, name='toxics_output')\n",
    "    toxics_result = K.binary_crossentropy(toxics, toxics_output)\n",
    "#     print('toxic_result {}'.format(toxics_result))\n",
    "#     weighted_toxics_result = toxics_result * toxic_weighting\n",
    "#     print('weighted_toxic_result {}'.format(weighted_toxics_result))\n",
    "#     print ('sum {}'.format((non_toxics_result + toxics_result)))\n",
    "#     print ('weighted sum {}'.format((non_toxics_result + weighted_toxics_result)))\n",
    "\n",
    "    return K.mean(non_toxics_result) + (K.mean(toxics_result) * toxic_weighting)\n",
    "\n",
    "def init_weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "\n",
    "    def weight_binary_crossentropy(y_true, y_pred):\n",
    "        b_ce = K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "        # Apply the weights\n",
    "        weight_vector = (y_true * one_weight) + ((1. - y_true) * zero_weight)\n",
    "        weighted_b_ce = weight_vector * b_ce\n",
    "\n",
    "        # Return the mean error\n",
    "        return K.mean(weighted_b_ce)\n",
    "    \n",
    "    return weight_binary_crossentropy\n",
    "\n",
    "input_model = Sequential()\n",
    "input_model.add(embedding)\n",
    "input_model.add(GRU(32))\n",
    "input_model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "input_model.compile(optimizer='adam', loss=init_weighted_binary_crossentropy(0.001, 2), metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0,0,0], [0, 1, 0], [1, 0, 0]])\n",
    "weighted = (y_true) * 2 + (1. - y_true) * 0.0000001\n",
    "print(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3072\n",
    "\n",
    "def inputs():\n",
    "    padded_sequences = pad_sequences(sequences=sequences, maxlen=max_seq_len, padding='post')\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for sequence, y_train_val in zip(padded_sequences, y_train):\n",
    "        x_list.append(sequence)\n",
    "        y_list.append(y_train_val)\n",
    "    return np.array(x_list), np.array(y_list)\n",
    "\n",
    "x_inputs, y_inputs = inputs()\n",
    "\n",
    "hist = input_model.fit(x=x_inputs, y=y_inputs, epochs=6, batch_size=batch_size)\n",
    "\n",
    "print(hist.history.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = input_model.predict(x=x_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(y_pred)\n",
    "\n",
    "y_pred_labels = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    y_pred_labels[y_pred[:,i] > 0.5, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(y_pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_train, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-52.95945713886305"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
