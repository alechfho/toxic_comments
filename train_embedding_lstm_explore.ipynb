{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams, pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'total m = 159571'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "\n",
    "x_train = df_train['comment_text']\n",
    "y_train = df_train[categories].as_matrix()\n",
    "\n",
    "display(df_train.head())\n",
    "m = x_train.shape[0]\n",
    "display(f'total m = {m}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length 1403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vocabulary size 210337'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(texts=x_train)\n",
    "sequences = tokenizer.texts_to_sequences(texts=x_train)\n",
    "\n",
    "max_seq_len = 0\n",
    "for sequence in sequences:\n",
    "    max_seq_len = max(max_seq_len, len(sequence))\n",
    "\n",
    "print('max length {}'.format(max_seq_len))\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index)\n",
    "\n",
    "display('vocabulary size {}'.format(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten\n",
    "\n",
    "embedding_dim = 50\n",
    "train_embedding = Embedding(vocabulary_size + 1, embedding_dim, input_length=2, name='embedding')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(train_embedding)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, name='dense'))\n",
    "model.add(Activation('sigmoid', name='activation'))\n",
    "    \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [1:09:36<00:00, 38.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "negative_samples=5\n",
    "\n",
    "def skipgram_inputs_generator(epochs):\n",
    "    for i in range(epochs):\n",
    "        for sequence in sequences:\n",
    "            skipgram = skipgrams(sequence=sequence, vocabulary_size=vocabulary_size, negative_samples=negative_samples, shuffle=True)\n",
    "            if not skipgram[0]:\n",
    "                skipgram = np.zeros((1, 2)), np.zeros((1, 1))\n",
    "            yield np.array(skipgram[0]), np.array(skipgram[1])\n",
    "            \n",
    "def skipgram_inputs():\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for sequence in tqdm(sequences):\n",
    "        skipgram = skipgrams(sequence=sequence, vocabulary_size=vocabulary_size, negative_samples=negative_samples, shuffle=True)\n",
    "        if not skipgram[0]:\n",
    "            skipgram = np.zeros((1, 2)), np.zeros((1, 1))\n",
    "        x_list.extend(skipgram[0]), y_list.extend(skipgram[1])\n",
    "    return np.array(x_list), np.array(y_list)\n",
    "\n",
    "x_emb_train, y_emb_train = skipgram_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "503404686/503404686 [==============================] - 30523s 61us/step - loss: 0.1034 - acc: 0.9649\n",
      "Epoch 2/3\n",
      "503404686/503404686 [==============================] - 31136s 62us/step - loss: 0.1020 - acc: 0.9651\n",
      "Epoch 3/3\n",
      "503404686/503404686 [==============================] - 30994s 62us/step - loss: 0.1020 - acc: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110ef80f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit_generator(generator=skipgram_inputs_generator(3), epochs=3, steps_per_epoch=m)\n",
    "\n",
    "model.fit(x=x_emb_train, y=y_emb_train, batch_size=2048, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(vocabulary_size + 1, embedding_dim, weights=train_embedding.get_weights(), trainable=False)\n",
    "\n",
    "from keras.layers import Bidirectional, LSTM, GRU, Dense\n",
    "\n",
    "input_model = Sequential()\n",
    "input_model.add(embedding)\n",
    "input_model.add(GRU(32))\n",
    "input_model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "input_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "159571/159571 [==============================] - 715s 4ms/step - loss: 0.1962 - acc: 0.9633\n",
      "Epoch 2/6\n",
      "159571/159571 [==============================] - 716s 4ms/step - loss: 0.1415 - acc: 0.9633\n",
      "Epoch 3/6\n",
      "159571/159571 [==============================] - 715s 4ms/step - loss: 0.1411 - acc: 0.9633\n",
      "Epoch 4/6\n",
      "159571/159571 [==============================] - 715s 4ms/step - loss: 0.1411 - acc: 0.9633\n",
      "Epoch 5/6\n",
      "159571/159571 [==============================] - 712s 4ms/step - loss: 0.1411 - acc: 0.9633\n",
      "Epoch 6/6\n",
      "159571/159571 [==============================] - 711s 4ms/step - loss: 0.1411 - acc: 0.9633\n",
      "dict_items([('loss', [0.19623128491449104, 0.1415041312673859, 0.14113456604022362, 0.14108743809183694, 0.14107719545669301, 0.1410680396924737]), ('acc', [0.96334541684257968, 0.96334542039896409, 0.96334542155877656, 0.96334542036273163, 0.96334542457242101, 0.96334541375908489])])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "def inputs():\n",
    "    padded_sequences = pad_sequences(sequences=sequences, maxlen=max_seq_len, padding='post')\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for sequence, y_train_val in zip(padded_sequences, y_train):\n",
    "        x_list.append(sequence)\n",
    "        y_list.append(y_train_val)\n",
    "    return np.array(x_list), np.array(y_list)\n",
    "\n",
    "x_inputs, y_inputs = inputs()\n",
    "\n",
    "hist = input_model.fit(x=x_inputs, y=y_inputs, epochs=6, batch_size=batch_size)\n",
    "\n",
    "print(hist.history.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = input_model.predict(x=x_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.009448  ],\n",
       "       [ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.009448  ],\n",
       "       [ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.009448  ],\n",
       "       ..., \n",
       "       [ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.00944801],\n",
       "       [ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.00944801],\n",
       "       [ 0.10204051,  0.01067148,  0.05488576,  0.00293399,  0.0514012 ,\n",
       "         0.00944801]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_pred)\n",
    "\n",
    "y_pred_labels = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    y_pred_labels[y_pred[:,i] > 0.5, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89832112351241766"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_train, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_weights = train_embedding.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('output/embedding_weights_20180312', embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
