{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams, pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'total m = 159571'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length 1403\n",
      "min length 1\n"
     ]
    }
   ],
   "source": [
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "df_train = pd.read_csv('input/train.csv')\n",
    "\n",
    "x_train = df_train['comment_text']\n",
    "y_train = df_train[categories].as_matrix()\n",
    "\n",
    "display(df_train.head())\n",
    "m = x_train.shape[0]\n",
    "display(f'total m = {m}')\n",
    "\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(texts=x_train)\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index)\n",
    "sequences = tokenizer.texts_to_sequences(texts=x_train)\n",
    "\n",
    "max_seq_len = 0\n",
    "for sequence in sequences:\n",
    "    max_seq_len = max(max_seq_len, len(sequence))\n",
    "\n",
    "print('max length {}'.format(max_seq_len))\n",
    "\n",
    "min_seq_len = max_seq_len\n",
    "for sequence in sequences:\n",
    "    min_seq_len = min(min_seq_len, len(sequence))\n",
    "    \n",
    "print('min length {}'.format(min_seq_len))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.221569082101382"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(x) for x in sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9883534256840718, 4.248940284069297, 2.5817659291353974, 5.4539585667967865, 2.6518668995849177, 4.375776717520396]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "embedding_dim = 50\n",
    "weights = np.load('output/embedding_weights_20180312.npy')\n",
    "\n",
    "embedding = Embedding(vocabulary_size + 1, embedding_dim, weights=weights, trainable=False)\n",
    "\n",
    "from keras.layers import Bidirectional, LSTM, GRU, Dense\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "toxic_weighting = 2.0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def init_weighted_binary_crossentropy(one_weights, zero_weights):\n",
    "\n",
    "    def weight_binary_crossentropy(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), (1.0 - K.epsilon()))\n",
    "        \n",
    "        o_terms = tf.multiply(tf.multiply(y_true, tf.log(y_pred)), one_weights)\n",
    "        z_terms = tf.multiply(tf.subtract(1.0, y_true), tf.log(tf.subtract(1.0, y_pred)))\n",
    "\n",
    "        terms = tf.add(o_terms, z_terms)\n",
    "        terms = tf.negative(K.mean(terms))\n",
    "\n",
    "        return K.mean(terms)\n",
    "    \n",
    "    return weight_binary_crossentropy\n",
    "\n",
    "input_model = Sequential()\n",
    "input_model.add(embedding)\n",
    "input_model.add(Bidirectional(LSTM(64)))\n",
    "input_model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "c_count = [15294, 1595, 8449, 478, 7877, 1405]\n",
    "o_weights = [max(1.0, math.log(0.70 * m / float(c))) for c in c_count]\n",
    "print(o_weights)\n",
    "z_weights = np.zeros(6)\n",
    "\n",
    "input_model.compile(optimizer='adam', loss=init_weighted_binary_crossentropy(o_weights, z_weights), metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159571/159571 [==============================] - 186s 1ms/step - loss: 0.3407 - categorical_accuracy: 0.7108\n",
      "Epoch 2/20\n",
      "159571/159571 [==============================] - 192s 1ms/step - loss: 0.2819 - categorical_accuracy: 0.9241\n",
      "Epoch 3/20\n",
      "159571/159571 [==============================] - 188s 1ms/step - loss: 0.2775 - categorical_accuracy: 0.9554\n",
      "Epoch 4/20\n",
      "159571/159571 [==============================] - 188s 1ms/step - loss: 0.2739 - categorical_accuracy: 0.9421\n",
      "Epoch 5/20\n",
      "159571/159571 [==============================] - 191s 1ms/step - loss: 0.2673 - categorical_accuracy: 0.9313\n",
      "Epoch 6/20\n",
      "159571/159571 [==============================] - 198s 1ms/step - loss: 0.2568 - categorical_accuracy: 0.9426\n",
      "Epoch 7/20\n",
      "159571/159571 [==============================] - 188s 1ms/step - loss: 0.2535 - categorical_accuracy: 0.9495\n",
      "Epoch 8/20\n",
      "159571/159571 [==============================] - 190s 1ms/step - loss: 0.2435 - categorical_accuracy: 0.9581\n",
      "Epoch 9/20\n",
      "159571/159571 [==============================] - 187s 1ms/step - loss: 0.2412 - categorical_accuracy: 0.9548\n",
      "Epoch 10/20\n",
      "159571/159571 [==============================] - 189s 1ms/step - loss: 0.2342 - categorical_accuracy: 0.9643\n",
      "Epoch 11/20\n",
      "159571/159571 [==============================] - 191s 1ms/step - loss: 0.2285 - categorical_accuracy: 0.9587\n",
      "Epoch 12/20\n",
      "159571/159571 [==============================] - 189s 1ms/step - loss: 0.2255 - categorical_accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "159571/159571 [==============================] - 189s 1ms/step - loss: 0.2239 - categorical_accuracy: 0.9537\n",
      "Epoch 14/20\n",
      "159571/159571 [==============================] - 189s 1ms/step - loss: 0.2219 - categorical_accuracy: 0.9552\n",
      "Epoch 15/20\n",
      "159571/159571 [==============================] - 190s 1ms/step - loss: 0.2141 - categorical_accuracy: 0.9735\n",
      "Epoch 16/20\n",
      "159571/159571 [==============================] - 191s 1ms/step - loss: 0.2153 - categorical_accuracy: 0.9734\n",
      "Epoch 17/20\n",
      "159571/159571 [==============================] - 193s 1ms/step - loss: 0.2168 - categorical_accuracy: 0.9670\n",
      "Epoch 18/20\n",
      "159571/159571 [==============================] - 194s 1ms/step - loss: 0.2084 - categorical_accuracy: 0.9731\n",
      "Epoch 19/20\n",
      "159571/159571 [==============================] - 195s 1ms/step - loss: 0.2071 - categorical_accuracy: 0.9743\n",
      "Epoch 20/20\n",
      "159571/159571 [==============================] - 196s 1ms/step - loss: 0.2026 - categorical_accuracy: 0.9764\n",
      "dict_items([('loss', [0.34074443263684417, 0.2818681114807482, 0.27754681579824081, 0.27389591039838868, 0.26729537701827283, 0.25675827328538092, 0.25345750279738277, 0.24349939269811804, 0.24115482206150995, 0.23422783297207442, 0.22853277482879084, 0.22547081999436414, 0.22389961879653333, 0.22194479719589613, 0.21411467051836766, 0.21533431935822175, 0.21684206476135109, 0.2084069662868826, 0.20713438770546325, 0.2026038954302094]), ('categorical_accuracy', [0.7108434464198905, 0.9241027502954563, 0.95536156752201995, 0.94212607490279865, 0.93131583942807816, 0.94261488480163358, 0.94953343053787176, 0.95806255180951627, 0.95477875010499635, 0.96431682644855521, 0.95865163767592776, 0.97210646424475888, 0.95373219411690535, 0.95516729258524868, 0.97349142307532066, 0.97337235333379835, 0.967049151065285, 0.97312794355201604, 0.97426850559069422, 0.9763866883941128])])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3072\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def inputs():\n",
    "    padded_sequences = pad_sequences(sequences=sequences, maxlen=max_len, padding='post')\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for sequence, y_train_val in zip(padded_sequences, y_train):\n",
    "        x_list.append(sequence)\n",
    "        y_list.append(y_train_val)\n",
    "    return np.array(x_list), np.array(y_list)\n",
    "\n",
    "x_inputs, y_inputs = inputs()\n",
    "\n",
    "hist = input_model.fit(x=x_inputs, y=y_inputs, epochs=20, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(hist.history.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = input_model.predict(x=x_inputs[0:1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.89519352, 0.82692993, 0.90450907, 0.41762441, 0.90842015, 0.56149977]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04515218,  0.00324848,  0.02079026,  0.00253346,  0.02343567,\n",
       "         0.00421558],\n",
       "       [ 0.11117588,  0.01238674,  0.06037787,  0.00652811,  0.0509252 ,\n",
       "         0.01808086],\n",
       "       [ 0.05455003,  0.00463146,  0.04517697,  0.00419739,  0.03413592,\n",
       "         0.00487014],\n",
       "       ..., \n",
       "       [ 0.0293682 ,  0.00140283,  0.01754333,  0.00195153,  0.01610556,\n",
       "         0.00315573],\n",
       "       [ 0.01945841,  0.00098746,  0.01308971,  0.00067254,  0.00921343,\n",
       "         0.00192902],\n",
       "       [ 0.06026293,  0.00364184,  0.03679466,  0.00436013,  0.03072782,\n",
       "         0.00960463]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_max = [np.max(y_pred[:,i]) for i in range(len(categories))]\n",
    "\n",
    "display(cat_max)\n",
    "\n",
    "display(y_pred)\n",
    "\n",
    "y_pred_labels = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n",
    "\n",
    "for cmax, i in zip(cat_max, range(len(categories))):\n",
    "    y_pred_labels[y_pred[:,i] >= cmax, i] = 1\n",
    "    y_pred_labels[y_pred[:,i] < cmax, i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_pred_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89200000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train[0:1000,:], y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164,)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('input/test.csv')\n",
    "\n",
    "x_test = df_test['comment_text']\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164\n"
     ]
    }
   ],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "padded_sequences_test = pad_sequences(sequences=sequences_test, maxlen=max_len, padding='post')\n",
    "\n",
    "print(len(padded_sequences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = input_model.predict(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n",
      "[0.97336537, 0.91963977, 0.96198243, 0.68882245, 0.96235347, 0.81159014]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred.shape)\n",
    "\n",
    "test_cat_max = [np.max(y_test_pred[:,i]) for i in range(len(categories))]\n",
    "\n",
    "print(test_cat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_labels = np.zeros((y_test_pred.shape[0], y_test_pred.shape[1]))\n",
    "\n",
    "print(y_test_pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred_labels[y_test_pred[:,0] >= 0.90, 0] = 1\n",
    "y_test_pred_labels[y_test_pred[:,1] >= 0.90, 1] = 1\n",
    "y_test_pred_labels[y_test_pred[:,2] >= 0.90, 2] = 1\n",
    "y_test_pred_labels[y_test_pred[:,3] >= 0.60, 3] = 1\n",
    "y_test_pred_labels[y_test_pred[:,4] >= 0.90, 4] = 1\n",
    "y_test_pred_labels[y_test_pred[:,5] >= 0.80, 5] = 1\n",
    "\n",
    "\n",
    "display(y_test_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "df_submission = pd.DataFrame()\n",
    "df_submission['id'] = df_test['id']\n",
    "for c, i in zip(categories, range(len(categories))):\n",
    "    df_submission[c] = y_test_pred_labels[:, i]\n",
    "\n",
    "    \n",
    "print(df_submission.shape)\n",
    "\n",
    "df_submission.to_csv('output/lstm_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
